<!DOCTYPE html>

<html>
    <head>
        <link rel="stylesheet" href="bower_components/reveal.js/css/reveal.css">
        <link rel="stylesheet" href="bower_components/reveal.js/css/theme/black.css">

        <style>
          .reveal .slides section h2 {
            text-transform: none;
          }

          .reveal .slides section pre {
            color: white;
            background-color: black;
          }

          .reveal .slides section button {
            font-size: 2em;
          }

          .reveal .slides section h2.shadow {
            text-shadow: 3px 3px 3px #000;
            background: #ccc;
            }

          .banner {
            position:fixed;
            bottom:50px;
            background-color: #ccc;
            height: 250px;
            width: 100%;
            display: flex;
            justify-content: flex-start;
            align-items: flex-start;
          }

          .banner .title {
            justify-content: flex-start;
            font-size: 1em;
            text-align: left;
            padding: 0.5em;
          }

          .banner .title h1 {
            justify-content: flex-start;
            font-size: 1.5em;
            text-transform: none;
            font-weight: bold;
          }

          .banner .title h2 {
            justify-content: flex-start;
            font-size: 1em;
            text-transform: none;
            font-style: italic;
          }


          .banner .bio {
            justify-content: flex-end;
            align-self: flex-end;
            font-size: 0.5em;
            text-align: right;
            padding: 0.5em;
          }

          .banner .bio a{
            color: #222;
          }

          .bio-page {
            display: flex;
            justify-content: flex-start;
            align-items: flex-start;
          }

          .bio-page .bio-right {
            text-align: right;
            padding: 0.5em;

          }

        </style>

        <script type="text/javascript">
          function sayHello(){
            var msg = new SpeechSynthesisUtterance('Hello World');
            window.speechSynthesis.speak(msg);
          }
        </script>
    </head>
    <body>
        <div class="reveal">
            <div class="slides">
                <section data-background-image="img/conversation-799448_1280.png"
                         data-background-color="#ffffff">
                  <div class="banner">
                    <div class="title">
                      <h1>Conversational UIs</h1>
                      <h2>Talking to Siri, Alexa, and Your Web Browser</h2>
                    </div>
                    <div class="bio">
                      Scott Davis <br>
                      <a href="mailto:sdavis@thoughtworks.com">sdavis@thoughtworks.com</a> <br>
                      <a href="https://twitter.com/scottdavis99?lang=en">@scottdavis99</a>
                    </div>
                  </div>

                  <aside class="notes">
                    Conversational UIs: Talking to Siri, Alexa, and your web browser.
                  </aside>
                </section>

                <section>
                  <div class="bio-page">
                    <img src="img/scott_davis_2012.jpg" alt="">
                    <div class="bio-right">
                      <p>Scott Davis</p>
                      <img src="img/thoughtworks-logo-2.png" alt="">
                      <img src="img/ibm_dW1.png" alt="">
                      <img src="img/oreilly-logo.png" alt="">
                    </div>
                  </div>

                  <aside class="notes">
                    Hi! My name is Scott Davis. I'm a Principal Engineer with ThoughtWorks. I'm an author as well. Over the years, I've written for IBM developerWorks, O'Reilly, and the Pragmatic Bookshelf.
                  </aside>
                </section>

                <section>
                  <p><a href="https://github.com/ThirstyHead/conversational-ui">https://github.com/ThirstyHead/conversational-ui</a></p>
                  <a href="https://github.com/ThirstyHead/conversational-ui"><img src="img/presentation-github.png" alt=""></a>
                </section>

                <section>
                  <a href="https://backchannel.com/voice-is-the-next-big-platform-and-alexa-will-own-it-c2cf13fab911#.a81t7r5cb"><img src="img/backchannel-voice-is-big.png" alt=""></a>
                  <aside class="notes">
                    Voice interfaces, or "Conversational UIs", are an increasingly standard feature on just about every new electronic device you purchase these days.
                    My family got an Amazon Echo for Christmas this year, and it's amazing how quickly we've all gotten used to walking into the kitchen and saying, "Hey Alexa, play some Beatles for me." Since the Echo lacks a keyboard and a screen, we all expected to talk to Alexa from the very beginning.
                    What caught us by surprise was pressing the search button on our new Roku remote control. Instead of pulling up an on-screen keyboard on our TV, it prompted us to hold the remote to our mouth and speak the name of the show we were hoping to watch. The voice recognition was freakishly accurate, and much faster than having to peck out one letter at a time using up, down, left, and right on the remote control.
                  </aside>
                </section>

                <section>
                  <a href="https://www.gartner.com/doc/3021226/market-trends-voice-ui-consumer"><img src="img/gartner-voice-ui.png" alt=""></a>

                  <aside class="notes">
                    Saying, "Hey Siri," "Hey Google", or "Hey Cortana" to your Apple, Google, or Microsoft smartphone doesn't seem like that big of a stretch in terms of user experiences -- after all, talking to your phone is kind of what you already expected to do. But what about talking to your refrigerator, or your toaster, or your washing machine? Or, in the case of Alexa, just talking to thin air as you walk into a room? This is going to become increasingly commonplace. Gartner predicts that by 2018, 30% of all interactions with technology will be done through conversations.
                  </aside>
                </section>



                <section>
                  <a href="https://www.fastcodesign.com/3058546/conversational-interfaces-explained"><img src="img/fastcompany-conversational-ui.png" alt=""></a>
                  <aside class="notes">
                    Satya Nadella -- the CEO of Microsoft -- went so far as to say, "The future of Microsoft is 'conversation as platform'." I'm having a hard time disagreeing with him.
                  </aside>
                </section>

                <section>
                  <a href="https://www.fastcodesign.com/3058546/conversational-interfaces-explained"><img src="img/fastcompany-conversational-ui-types.png" alt=""></a>
                  <aside class="notes">
                    So, what is a Conversational UI? To me, it means speaking to a computer as if it were a human, instead of forcing humans to talk to computers in their native language.

                    I'm not suggesting that you can't have a meaningful conversation with your computer by typing on a keyboard at the command line or in a chat window. Chatbots and texting are gaining popularity as new ways to interface with your computer in a more casual manner, but for the purposes of this presentation, I'm going to focus on talking rather than typing.
                  </aside>
                </section>

                <section data-background-color="#ffffff">
                  <h2>WarGames: Chatbots from 1983</h2>
                  <a href="https://www.youtube.com/watch?v=D-9l5jSDL50"><img src="img/wargames.jpg" alt=""></a>

                  <aside class="notes">
                    The movie "WarGames" came out in 1983, just a couple years after the personal computer was introduced to the home market. It did a great job of capturing the excitement and potential of how these new, unfamiliar devices could change our everyday lives. (You can click on the image to watch a short clip from the movie.)

                    Notice how quickly Matthew Broderick explains what a Conversational UI is to his girlfriend. "It'll ask you whatever it's programmed to ask you. Would you like to hear it talk?"

                    "How can it talk?" she asks. "It's not a real voice," he replies. "This box just determines signals from the computer and turns them into sound."
                  </aside>
                </section>

                <section>
                  <h2>Web Speech API</h2>
                  <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API"><img src="img/mdn-web-speech-api.png" alt=""></a>

                  <aside class="notes">
                    Here we are almost 35 years later, and the Web Speech API allows you to do the same thing in any modern browser.

                    Notice that the API is broken into two parts. The SpeechSynthesis part of the API takes text and converts it to spoken words, just like what you saw in WarGames.

                    The SpeechRecognition interface -- going in the opposite direction, converting spoken words into text -- is devilishly more complex. Only recently, with advances in Artificial Intelligence and Machine Learning, coupled with nearly ubiquitous Internet connectivity and Cloud Computing, have allowed friendly agents like Siri and Alexa to become not only possible, but mainstream.
                  </aside>
                </section>

                <section>
                  <p><a href="http://caniuse.com/#feat=speech-synthesis">http://caniuse.com/#feat=speech-synthesis</a></p>
                  <a href="http://caniuse.com/#feat=speech-synthesis"><img src="img/caniuse-speech-synthesis-api.png" alt=""></a>

                  <aside class="notes">
                    If you go to "can i use dot com" in your browser and type in "speech synthesis", you'll see that it is universally available in every modern browser that you care about. And it's ridiculously easy to implement as well.
                  </aside>
                </section>

                <section data-background-color="#ffffff">
                  <pre><code>
var msg = new SpeechSynthesisUtterance('Hello World');
window.speechSynthesis.speak(msg);
                  </code></pre>

                  <button onclick="sayHello()">Say Hello</button>

                  <aside class="notes">
                    To add SpeechSynthesis to your webpage, it literally requires two lines of code. The first line will "new up" a SpeechSynthesisUtterance object, passing in your text string as the only constructor argument. In the next line of code, you simply ask the SpeechSynthesis API to speak your new utterance.

                    Click the "Say Hello" button to hear this code in action.

                    For more information on this, do a web search on "MDN SpeechSynthesisUtterance". This will return a link to the Mozilla Developer Network article. The Mozilla organization is, of course, who brings you the Firefox web browser. I find their JavaScript documentation to be among the best on the Internet.
                  </aside>
                </section>

                <section>
                  <p><a href="https://github.com/mdn/web-speech-api/">https://github.com/mdn/web-speech-api/</a></p>
                  <a href="https://github.com/mdn/web-speech-api/"><img src="img/mdn-web-speech-api-github.png" alt=""></a>

                  <aside class="notes">
                    For a more involved example of the SpeechSynthesis API, go to github.com/mdn/web-speech-api and download the code. This doesn't require any plugins or additional libraries, and will run in any modern browser. Look especially at the Speak Easy synthesis project for ideas on how you can adjust the voice, the pitch, and the rate of speech that the SpeechSynthesis API can use. 
                  </aside>
                </section>


                <section>
                  <h2>Apple's Conversational UI (1987)</h2>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/umJsITGzXd0" frameborder="0" allowfullscreen></iframe>
                  <aside class="notes">
                    Let me play you a quick video that Apple has released promoting their conversational UI.
                  </aside>
                </section>

                <section>
                  <h2>Siri (2011)</h2>
                  <a href="http://www.apple.com/ios/siri/"><img src="img/siri-home.png" alt=""></a>
                </section>

                <section>
                  <a href="https://en.wikipedia.org/wiki/Siri"><img src="img/siri-wikipedia.png" alt=""></a>
                </section>

                <section data-background-image="img/light-bulb-1407610_1280.jpg">
                  <h2 class="shadow">Speech Recognition === Cloud</h2>
                  <aside class="notes">
                    Speech-to-text is devilishly difficult, and currently requires either cloud access or proprietary software that requires specialized training to learn your voice.
                  </aside>
                </section>

                <section>
                  <a href="https://en.wikipedia.org/wiki/Siri"><img src="img/siri-history-wikipedia.png" alt=""></a>
                </section>

                <section>
                  <a href="https://techcrunch.com/2016/03/23/google-opens-access-to-its-speech-recognition-api-going-head-to-head-with-nuance/"><img src="img/google-speech-recognition-techcrunch.png" alt=""></a>
                </section>

                <section>
                  <a href="https://cloud.google.com/blog/big-data/2017/01/new-features-in-the-google-cloud-natural-language-api-thanks-to-your-feedback"><img src="img/google-cloud-natural-language-api.png" alt=""></a>
                </section>


                <section>
                  <p><a href="http://caniuse.com/#feat=speech-recognition">http://caniuse.com/#feat=speech-recognition</a></p>
                  <a href="http://caniuse.com/#feat=speech-recognition"><img src="img/caniuse-speech-recognition-api.png" alt=""></a>
                </section>

                <section>
                  <p><a href="https://github.com/mdn/web-speech-api/">https://github.com/mdn/web-speech-api/</a></p>
                  <a href="https://github.com/mdn/web-speech-api/"><img src="img/mdn-web-speech-api-github.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/jsgf/"><img src="img/jsgf-w3c.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/jsgf/"><img src="img/jsgf-w3c-intro.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/jsgf/"><img src="img/jsgf-w3c-example.png" alt=""></a>
                </section>

                <section>
                  <h2>Live Speech-to-Text Demo</h2>
                  <a href="https://www.google.com/intl/en/chrome/demos/speech.html">https://www.google.com/intl/en/<br>chrome/demos/speech.html</a>
                </section>

                <section>
                  <a href="https://developers.google.com/web/updates/2013/01/Voice-Driven-Web-Apps-Introduction-to-the-Web-Speech-API"><img src="img/web-speech-recognition-google.png" alt=""></a>
                </section>


                <section>
                  <a href="https://smile.amazon.com/Amazon-Echo-Bluetooth-Speaker-with-WiFi-Alexa/dp/B00X4WHP5E/ref=sr_1_1?ie=UTF8&qid=1484605178&sr=8-1&keywords=echo"><img src="img/amazon-echo-home.png" alt=""></a>
                </section>

                <section>
                  <a href="http://fortune.com/2015/06/25/amazon-alexa-fund/"><img src="img/amazon-echo-fortune.png" alt=""></a>
                </section>

                <section>
                  <p><a href="https://github.com/alexa/skill-sample-nodejs-fact">https://github.com/alexa/skill-sample-nodejs-fact</a></p>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github.png" alt=""></a>
                </section>

                <section>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-readme.png" alt=""></a>
                </section>

                <!-- Steps -->
                <section>
                  <h2>Step 1.</h2>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step01.png" alt=""></a>
                </section>

                <section>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step01b.png" alt=""></a>
                </section>

                <section>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step01c.png" alt=""></a>
                </section>

                <section>
                  <h2>Step 2.</h2>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step02.png" alt=""></a>
                </section>

                <section>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step02b.png" alt=""></a>
                </section>

                <section>
                  <h2>Step 3.</h2>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step03.png" alt=""></a>
                </section>

                <section>
                  <h2>Step 4.</h2>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step04.png" alt=""></a>
                </section>

                <section>
                  <a href="https://github.com/alexa/skill-sample-nodejs-fact"><img src="img/alexa-github-step04b.png" alt=""></a>
                </section>
                <!-- Steps -->

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-intro.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-steps.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-step01.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-step03.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-step04.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-step05.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-example.png" alt=""></a>
                </section>

                <section>
                  <a href="https://www.w3.org/TR/speech-synthesis/"><img src="img/ssml-w3c-example02.png" alt=""></a>
                </section>

                <section>
                  <p><a href="https://github.com/mdn/web-speech-api/">https://github.com/mdn/web-speech-api/</a></p>
                  <a href="https://github.com/mdn/web-speech-api/"><img src="img/mdn-web-speech-api-github.png" alt=""></a>
                </section>

                <section>
                  <h2>Web Speech API</h2>
                  <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API"><img src="img/mdn-web-speech-api.png" alt=""></a>
                </section>

                <section>
                  <a href="https://backchannel.com/voice-is-the-next-big-platform-and-alexa-will-own-it-c2cf13fab911#.a81t7r5cb"><img src="img/backchannel-voice-is-big.png" alt=""></a>
                  <aside class="notes">
                    Article on backchannel.com: "Voice Is the Next Big Platform, and Alexa Will Own It". The title of this article makes an important point -- 'Alexa' is the Voice UI; 'Echo' is simply one of many platforms Alexa is licensed to run on.
                  </aside>
                </section>

                <section>
                  <a href="https://www.gartner.com/doc/3021226/market-trends-voice-ui-consumer"><img src="img/gartner-voice-ui.png" alt=""></a>
                </section>

                <section data-background-image="img/conversation-799448_1280.png"
                         data-background-color="#ffffff">
                  <div class="banner">
                    <div class="title">
                      <h1>Conversational UIs</h1>
                      <h2>Talking to Siri, Alexa, and Your Web Browser</h2>
                    </div>
                    <div class="bio">
                      Scott Davis <br>
                      <a href="mailto:sdavis@thoughtworks.com">sdavis@thoughtworks.com</a> <br>
                      <a href="https://twitter.com/scottdavis99?lang=en">@scottdavis99</a>
                    </div>
                  </div>
                </section>

            </div>
        </div>
        <script src="bower_components/reveal.js/js/reveal.js"></script>
        <script>
            Reveal.initialize({
              // Display controls in the bottom right corner
              controls: false,

              // Display a presentation progress bar
              progress: false,

              // Push each slide change to the browser history
              history: true,

              // Transition style
              transition: 'fade', // none/fade/slide/convex/concave/zoom

              // Flags if speaker notes should be visible to all viewers
              showNotes: false
            });
        </script>
    </body>
</html>
